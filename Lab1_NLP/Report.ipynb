{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've conducted some experiments with different architecures, so here are the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name | Encoder | Decoder | Attention | BPE(N_SYM) | N_epochs | PE(denom) | BLEU | training time | VideoRAM\n",
    "-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|\n",
    "Radoslav's initial | LSTM | LSTM | - | - | 10 | - | 14.28 | 14min | -\n",
    "From 2nd HW | LSTM | LSTM | Concat | - | 10 | - | 26.37 | 106min | 12000\n",
    "Init with BPE 1 | LSTM | LSTM | - | 10000 | 10 | - | 10.23 | 18min | 6500\n",
    "Init with BPE 2 | LSTM | LSTM | - | 20000 | 10 | - | 9.65 | 19min | 5100\n",
    "Init with BPE 3 | LSTM | LSTM | - | 40000 | 10 | - | 9.39 | 20min | 4400\n",
    "Self-attention  | CNN  | GRU  | self-attention | - | 10 | - | 9.66 | 23min | 10433\n",
    "Self-attention + PE 1  | CNN  | GRU  | self-attention | - | 10 | 50 | 6 | 21min | 8500\n",
    "Self-attention  + PE 2 | CNN  | GRU  | self-attention | - | 10 | 1000 | 7.38 | 21min | 8500\n",
    "Self-attention  + PE 3 | CNN  | GRU  | self-attention | - | 10 | 10000 | 6.9 | 21min | 8500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see:\n",
    "- BPE does not give any increase in quality, using word-level tokenizer is reasonable\n",
    "- Classical seq2seq with classical attention performs really good but it needs a lot of time and videoRAM to train\n",
    "- CNN encoder with self-attention does not perform good, I think it is because it needs more data\n",
    "- Positional encoding also does not increase score, may be I should concatenate him with embedding but not add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to skoltech for GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
